# ============================================================
# ORACLE AI SERVICE - ENVIRONMENT CONFIGURATION
# ============================================================
# Copy this file to .env and fill in your values
# cp .env.example .env
# ============================================================

# ============================================================
# DATABASE (REQUIRED)
# ============================================================
# PostgreSQL connection details
# For Render: Use internal database URL components
# For local: Use your local PostgreSQL credentials

ORACLE_DB_USER=oracle_ai_user
ORACLE_DB_PASSWORD=your_secure_password_here
ORACLE_DB_HOST=localhost
ORACLE_DB_PORT=5432
ORACLE_DB_NAME=oracle_ai

# ============================================================
# REDIS (REQUIRED)
# ============================================================
# Used for: Caching, Rate limiting, Celery task queue
#
# CONNECTION PROTOCOL:
#   rediss:// = TLS/SSL encrypted (use for Render, Upstash, Redis Cloud)
#   redis://  = Unencrypted (use for local development only)
#
# For Render: Use internal Redis URL with rediss://
# For local:  redis://localhost:6379

REDIS_URL=rediss://your-redis-host:6379

# ============================================================
# CELERY - BACKGROUND TASKS (REQUIRED)
# ============================================================
# Uses Redis as broker and result backend
# Use different DB numbers to separate concerns
# IMPORTANT: Use same protocol (rediss:// or redis://) as REDIS_URL

CELERY_BROKER_URL=rediss://your-redis-host:6379/1
CELERY_RESULT_BACKEND=rediss://your-redis-host:6379/2

# ============================================================
# AI ENRICHMENT - TAVILY (REQUIRED FOR ENRICHMENT)
# ============================================================
# Get your API key from: https://tavily.com
# Pricing: ~$0.01 per search
# Used for: Web search to find user profiles

TAVILY_API_KEY=tvly-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================
# AI ENRICHMENT - ANTHROPIC (REQUIRED FOR ENRICHMENT)
# ============================================================
# Get your API key from: https://console.anthropic.com
# Pricing: $0.25/1M input tokens (Haiku model)
# Used for: Extracting structured data from search results

ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================
# GITHUB PUBLIC API (OPTIONAL - RECOMMENDED)
# ============================================================
# Get a Personal Access Token from: https://github.com/settings/tokens
# Benefits: Increases rate limit from 60/hr to 5000/hr
# Scopes needed: (none - public data only)

GITHUB_PUBLIC_API_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ============================================================
# RATE LIMITING CONFIGURATION
# ============================================================
# Adjust based on your API plan limits

# Tavily: Free tier = 100/month, Paid = varies
TAVILY_RATE_LIMIT=100
TAVILY_RATE_PERIOD_SECONDS=3600

# GitHub: 60/hr unauthenticated, 5000/hr with token
GITHUB_RATE_LIMIT=50
GITHUB_RATE_PERIOD_SECONDS=3600

# Anthropic: Depends on your plan
LLM_RATE_LIMIT=500
LLM_RATE_PERIOD_SECONDS=3600

# Per-user enrichment limit (prevents abuse)
USER_ENRICHMENT_RATE_LIMIT=5
USER_ENRICHMENT_RATE_PERIOD_SECONDS=3600

# Global enrichment throttle
ENRICHMENT_MAX_PER_HOUR=100

# ============================================================
# CIRCUIT BREAKER CONFIGURATION
# ============================================================
# Prevents cascade failures when external APIs are down

# Number of failures before circuit opens
CIRCUIT_BREAKER_FAIL_MAX=5

# Seconds before attempting to close circuit
CIRCUIT_BREAKER_TIMEOUT=60

# ============================================================
# CACHING TTL (SECONDS)
# ============================================================
# How long to cache external API responses

# Tavily search results: 24 hours
TAVILY_CACHE_TTL_SECONDS=86400

# GitHub profile data: 7 days
GITHUB_CACHE_TTL_SECONDS=604800

# Analytics computations: 1 hour
ANALYTICS_CACHE_TTL_SECONDS=3600

# ============================================================
# SECURITY CONFIGURATION
# ============================================================

# Max length for user input strings (prevents memory attacks)
MAX_INPUT_STRING_LENGTH=1000

# Max items in arrays (interests, skills)
MAX_ARRAY_INPUT_LENGTH=50

# Days to retain enrichment data (GDPR compliance)
ENRICHMENT_DATA_RETENTION_DAYS=365

# ============================================================
# ML MODEL CONFIGURATION
# ============================================================
# Sentiment analysis model (loaded from HuggingFace)

SENTIMENT_MODEL_NAME=distilbert-base-uncased-finetuned-sst-2-english

# ============================================================
# KAFKA (OPTIONAL - FOR EVENT STREAMING)
# ============================================================
# Only needed if using Kafka for inter-service communication
# Leave default if not using Kafka

KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# ============================================================
# GITHUB APP (OPTIONAL - FOR CI/CD WORKFLOWS)
# ============================================================
# Only needed if triggering GitHub Actions workflows
# Get from: GitHub App settings page

GITHUB_APP_ID=
GITHUB_INSTALLATION_ID=
GITHUB_PRIVATE_KEY=
GITHUB_WORKFLOW_DISPATCH_URL=

# ============================================================
# MONITORING - DATADOG (OPTIONAL)
# ============================================================
# Only needed if using Datadog for monitoring
# Get from: https://app.datadoghq.com/organization-settings/api-keys

DATADOG_API_KEY=
DATADOG_APP_KEY=
